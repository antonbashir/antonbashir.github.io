---
title: LLM usage principles
description: Handbook of principles for communication with LLM
date: "2025-08-08"
label: Guide
tags: LM, AI, IT
time: 5 min
---
Here on this site, I’ve already written a similar article about [modeling principles](/blog/en/modelling-principles). In this article, I’ve gathered my own thoughts on interacting with large language models.

Language models are a relatively new phenomenon, so these principles are more like thoughts than firm rules. They will change over time and eventually become stable enough to be considered principles.

Some of these thoughts may seem obvious. However, I plan to use this article as a reminder for myself, something to refer to when interacting with the model and not forgetting these principles.

These principles are neither positive nor negative in their judgment of language models as a whole. They are simply personal observations and guidelines.

1. Principle of Reliability. A language model operates with combinations from a certain set of information.
The user of the model does not have full knowledge of how this information was obtained. There is no clear mapping between the model’s output and the facts it presents.
Therefore, every output from the model must be verified against known factual arguments that confirm its truth.

2. Principle of Trust. When interacting with the model, there is a feeling of talking to an expert. This feeling should be treated with caution.
The reason for caution is that the user does not have enough information about how this "expert" was formed, its history, its path, its values.

3. Principle of Involvement. The user delegates tasks to the model. As a result, the model helps save the user’s attention and level of engagement.
With this approach, the user risks falling into an "involvement trap." If the model’s results are meant to be used long-term, not just at the moment of interaction, then future involvement must be considered.
The danger is that while saving engagement when delegating a task to the model, the user may end up needing twice as much engagement later when dealing with the consequences of that delegation.
It’s also worth noting that the model’s results, for example, generated code, may be used by others, not just the user.
This means there is a risk of increased involvement for those who will read and use the model’s output.
A separate issue is the involvement required to analyze the model’s results, this analysis is not free.

4. Principle of Opinion Alignment. A language model is not just a source of information. Its output may contain opinions, evaluations, or recommendations.
It’s important to consider how well the model’s "opinion" aligns with the user’s own views. The user may feel that the model "knows better" and that its opinion is more correct than theirs.
However, the model does not share the user’s value system. Because of this, the user should not replace their own opinion with the model’s.
Instead, the user should analyze the model’s output and compare it with their own views,never the other way around.

5. Principle of Volume. Many models tend to provide as much information as possible. The user must carefully assess the volume of information.
The more information there is, the harder it is to process. The user should remember to keep things concise when using the model’s output.

6. Principle of Wholeness. When a person engages in creative work, more happens in their body than just information processing.
Proper creative activity generates positive states. A synthesis of certain elements occurs, creating pleasant sensations in the person.
It’s important to remember these sensations when delegating tasks to a language model. During creative flow, people often don’t fully realize what’s happening within them, we rarely notice the exact sensations we experience.
By delegating creative tasks to the model, we risk missing out on the necessary amount of positive sensations and losing the right state of mind.

7. Principle of Task Formulation. Don’t approach the model with just a desire or a need. First, transform that need into a set of tasks, then approach the model with those tasks.
The reason is that every transformation of a need into tasks improves our internal modeling skill. The process of modeling itself should follow modeling principles.
This skill greatly helps in the future. Not developing it leads to a decline in the quality of creative work.

8. Principle of Context. If the user wants a high-quality solution to their task, the model must be informed about the context.
The environment in which the task’s solution will be applied is very important. The user must either provide enough context to the model or adapt the solution to the context themselves.

9. Principle of Learning. When solving creative tasks, we don’t just get results, we gain valuable skills. Our brain can extrapolate these skills to other challenges we face.
By delegating a task to the model, we don’t gain the full range of these skills.

10. Principle of Control. The user of the model cannot always clearly determine how the model works. If an algorithm we create ourselves is fully controllable, the model is not.

11. Principle of Resourcefulness. The model definitely saves an important resource - human attention. But if resources are saved in one place, they are spent elsewhere.
It’s important to understand what the user sacrifices when saving resources by using the model.

12. Principle of Feasibility. When the user formulates a request to the model, they must specify requirements based on available resources and tools.
The model’s output must be feasible, and its execution quality should meet the user’s expectations.